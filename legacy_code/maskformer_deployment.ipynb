{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tJ5u3q1t48Z5"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, UploadFile, HTTPException\n",
        "from fastapi.responses import FileResponse\n",
        "import os\n",
        "import subprocess\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "import aiofiles\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import functional as TF\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fastapi.responses import PlainTextResponse, JSONResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi import FastAPI, Request, Response\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app = FastAPI()\n",
        "\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JWO8QiOM5JeZ"
      },
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "[Errno 17] File exists: 'ecw_processing'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m GRID_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/grids\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m MASK_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/masks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(INPUT_DIR)\n\u001b[1;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(OUTPUT_DIR)\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'ecw_processing'"
          ]
        }
      ],
      "source": [
        "\n",
        "BASE_DIR = \"ecw_processing\"\n",
        "INPUT_DIR = f\"{BASE_DIR}/input\"\n",
        "OUTPUT_DIR = f\"{BASE_DIR}/output\"\n",
        "GRID_DIR = f\"{OUTPUT_DIR}/grids\"\n",
        "MASK_DIR = f\"{OUTPUT_DIR}/masks\"\n",
        "\n",
        "os.mkdir(BASE_DIR)\n",
        "os.mkdir(INPUT_DIR)\n",
        "os.mkdir(OUTPUT_DIR)\n",
        "os.mkdir(GRID_DIR)\n",
        "os.mkdir(MASK_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "baEKbJbFDWkb"
      },
      "outputs": [],
      "source": [
        "class RoadDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, scale_factor=0.5):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.tif\")))\n",
        "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.tif\")))\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.image_paths[idx])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        mask = (mask > 0).astype(np.uint8)\n",
        "\n",
        "        new_h = int(image.shape[0] * self.scale_factor)\n",
        "        new_w = int(image.shape[1] * self.scale_factor)\n",
        "\n",
        "        new_h += (32 - new_h % 32) % 32\n",
        "        new_w += (32 - new_w % 32) % 32\n",
        "\n",
        "        image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        mask = cv2.resize(mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "        return {\n",
        "            \"image\": TF.to_tensor(image),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.int64),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P2BmDcshD0GO"
      },
      "outputs": [],
      "source": [
        "class RoadSegmentationModel(pl.LightningModule):\n",
        "    def __init__(self, encoder_name=\"resnet34\", in_channels=3, classes=1):\n",
        "        super().__init__()\n",
        "        self.model = smp.create_model(\"FPN\", encoder_name=encoder_name, in_channels=in_channels, classes=classes)\n",
        "        self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def shared_step(self, batch):\n",
        "        images, masks = batch[\"image\"], batch[\"mask\"]\n",
        "        logits = self(images)\n",
        "        loss = self.loss_fn(logits, masks)\n",
        "        return loss, logits, masks\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, _, _ = self.shared_step(batch)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, logits, masks = self.shared_step(batch)\n",
        "        prob_masks = logits.sigmoid()\n",
        "        pred_masks = (prob_masks > 0.5).float()\n",
        "\n",
        "        pred_masks = pred_masks.to(torch.int64)\n",
        "\n",
        "        tp, fp, fn, tn = smp.metrics.get_stats(pred_masks, masks, mode=\"binary\")\n",
        "        iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_iou\", iou, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=25, eta_min=1e-5)\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"step\",\n",
        "                \"frequency\": 1,\n",
        "            },\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "road_model = RoadSegmentationModel()\n",
        "road_model.load_state_dict(torch.load(\"roads_trained_FPN.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvdp6-HuD-ig"
      },
      "outputs": [],
      "source": [
        "def single_image_inference(model, image_path, scale_factor=0.25):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        new_h = int(image.shape[0] * scale_factor)\n",
        "        new_w = int(image.shape[1] * scale_factor)\n",
        "        new_h = (new_h + 31) // 32 * 32\n",
        "        new_w = (new_w + 31) // 32 * 32\n",
        "        image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        image_tensor = TF.to_tensor(image).unsqueeze(0)\n",
        "\n",
        "        logits = model(image_tensor)\n",
        "        prob_mask = logits.sigmoid()\n",
        "        pred_mask = (prob_mask > 0.5).float().squeeze().cpu().numpy()\n",
        "\n",
        "        pred_mask = cv2.resize(pred_mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        return image, pred_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iRvwTLBxRd9"
      },
      "outputs": [],
      "source": [
        "@app.post(\"/process-ecw/\")\n",
        "async def process_ecw(file: UploadFile):\n",
        "    try:\n",
        "        file_id = str(uuid.uuid4())\n",
        "        ecw_file_path = INPUT_DIR / f\"{file_id}.ecw\"\n",
        "        async with aiofiles.open(ecw_file_path, 'wb') as f:\n",
        "            while chunk := await file.read(1024):\n",
        "                await f.write(chunk)\n",
        "\n",
        "        tiff_file_path = OUTPUT_DIR / f\"{file_id}.tif\"\n",
        "        gdal_translate_command = [\n",
        "            \"gdal_translate\", \"-of\", \"GTiff\", \"-co\", \"COMPRESS=LZW\",\n",
        "            str(ecw_file_path), str(tiff_file_path)\n",
        "        ]\n",
        "        subprocess.run(gdal_translate_command, check=True)\n",
        "\n",
        "        TILE_WIDTH, TILE_HEIGHT = 3000, 3000\n",
        "        ROWS, COLS = 5, 5\n",
        "        for row in range(ROWS):\n",
        "            for col in range(COLS):\n",
        "                x_offset = col * TILE_WIDTH\n",
        "                y_offset = row * TILE_HEIGHT\n",
        "                grid_file_path = GRID_DIR / f\"tile_{row}_{col}.tif\"\n",
        "                gdal_translate_grid_command = [\n",
        "                    \"gdal_translate\", \"-of\", \"GTiff\", \"-srcwin\",\n",
        "                    str(x_offset), str(y_offset), str(TILE_WIDTH), str(TILE_HEIGHT),\n",
        "                    str(tiff_file_path), str(grid_file_path)\n",
        "                ]\n",
        "                subprocess.run(gdal_translate_grid_command, check=True)\n",
        "\n",
        "        for grid_file in GRID_DIR.iterdir():\n",
        "            image, pred_mask = single_image_inference(None, str(grid_file))\n",
        "            mask_file_path = MASK_DIR / f\"mask_{grid_file.name}\"\n",
        "            cv2.imwrite(str(mask_file_path), (pred_mask * 255).astype(np.uint8))\n",
        "\n",
        "        combined_mask_tiff_path = OUTPUT_DIR / \"combined_masks.tif\"\n",
        "        gdalwarp_command = [\n",
        "            \"gdalwarp\", \"-of\", \"GTiff\", str(MASK_DIR / \"*.tif\"), str(combined_mask_tiff_path)\n",
        "        ]\n",
        "        subprocess.run(gdalwarp_command, check=True)\n",
        "\n",
        "        shapefile_path = OUTPUT_DIR / \"output_shapefile.shp\"\n",
        "        gdal_polygonize_command = [\n",
        "            \"gdal_polygonize.py\", str(combined_mask_tiff_path), \"-f\", \"ESRI Shapefile\",\n",
        "            str(shapefile_path)\n",
        "        ]\n",
        "        subprocess.run(gdal_polygonize_command, check=True)\n",
        "\n",
        "        return FileResponse(shapefile_path, media_type=\"application/x-shapefile\", filename=\"output_shapefile.zip\")\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3GhhYHOBIqm"
      },
      "outputs": [],
      "source": [
        "ngrok.set_auth_token(\"2WfNAfRBJZK6oe2x0Sl9QVRl5Zv_5wxr2UnS1CBuJmycrFk2k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngrok_tunnel = ngrok.connect(addr = 8000, domain = \"helpful-boxer-wrongly.ngrok-free.app\")\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
